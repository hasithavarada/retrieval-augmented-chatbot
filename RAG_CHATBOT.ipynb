{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaba95d1-7bd5-4d99-9253-6dd37df7e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89b480e9-b214-490d-9eaf-e46d3cb5f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n",
    "text = requests.get(url).text\n",
    "#text = text.replace(\"\\ufeff\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b796765-0d1e-422c-af4a-6d47155d5507",
   "metadata": {},
   "source": [
    "**CHUNKING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3a08956-3356-4c20-a4ab-042c7295f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\"\n",
    "end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\"\n",
    "\n",
    "text = text.split(start_marker)[-1]\n",
    "text = text.split(end_marker)[0]\n",
    "\n",
    "# Chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "#Convert long document into chunks\n",
    "chunks = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24895bd7-df13-40af-aeb7-42b4c4a71ea2",
   "metadata": {},
   "source": [
    "**EMBEDDINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b857834-6680-42b0-9e44-07a6866a4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 47/47 [00:40<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1488, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "chunk_embeddings = embedding_model.encode(\n",
    "    chunks,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings shape:\", chunk_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8cd400-c5b1-4f58-8cbf-1467151669e1",
   "metadata": {},
   "source": [
    "**VECTOR DATA BASE - FAISS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f24620e6-5561-4598-af68-a881ca90090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "faiss.normalize_L2(chunk_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9270b44-5e40-49fe-9f68-fe4c759a33bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors in FAISS index: 1488\n"
     ]
    }
   ],
   "source": [
    "dimension = chunk_embeddings.shape[1]  # 384\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "index.add(chunk_embeddings)\n",
    "\n",
    "print(\"Total vectors in FAISS index:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79c6f4-262c-423f-b4c8-8d7e628569e6",
   "metadata": {},
   "source": [
    "**Similarity search (Retrieval) question to embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "285d97c7-99c9-4de0-a7aa-ea9c70426754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity scores: [[0.682717  0.6724535 0.6599988]]\n",
      "\n",
      "--- Retrieved Chunk 1 ---\n",
      "opposing windows loomed like dark, shapeless blurs through the heavy\n",
      "yellow wreaths. Our gas was lit and shone on the white cloth and\n",
      "glimmer of china and metal, for the table had not been cleared yet.\n",
      "Sherlock Holmes had been silent all the morning, dipping continuously\n",
      "into the advertisement c\n",
      "\n",
      "--- Retrieved Chunk 2 ---\n",
      "He had hardly spoken before there rushed into the room one of the most\n",
      "lovely young women that I have ever seen in my life. Her violet eyes\n",
      "shining, her lips parted, a pink flush upon her cheeks, all thought of\n",
      "her natural reserve lost in her overpowering excitement and concern.\n",
      "\n",
      "“Oh, Mr. Sherl\n",
      "\n",
      "--- Retrieved Chunk 3 ---\n",
      "I wished to be absolutely clear. We shall now have a little supper and\n",
      "then retire, for we may have a very busy day to-morrow.”\n",
      "\n",
      "A large and comfortable double-bedded room had been placed at our\n",
      "disposal, and I was quickly between the sheets, for I was weary after\n",
      "my night of adventure. Sherloc\n"
     ]
    }
   ],
   "source": [
    "query = \"How is Sherlock Holmes described?\"\n",
    "\n",
    "query_embedding = embedding_model.encode(\n",
    "    [query],\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "faiss.normalize_L2(query_embedding)\n",
    "\n",
    "k = 3\n",
    "scores, indices = index.search(query_embedding, k) #using argmax here\n",
    "\n",
    "print(\"Cosine similarity scores:\", scores)\n",
    "\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"\\n--- Retrieved Chunk {i+1} ---\")\n",
    "    print(chunks[idx][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47d43e-4fbf-406d-b0c5-46ed6b10500f",
   "metadata": {},
   "source": [
    "**Context Construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4663f961-e337-43ef-8c78-8da5a1eeff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join([chunks[idx] for idx in indices[0]])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Answer the question ONLY using the given context.\n",
    "If the answer is not clearly stated, say \"Not explicitly mentioned in the context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea66145-fe38-4988-81e0-cd3e92da3441",
   "metadata": {},
   "source": [
    "**GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1876540b-a0b7-4346-9f6c-60de475a9ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man, however, who, when he had an unsolved problem upon his mind, would go for days, and even for a week, without rest, turning it over, rearranging his facts, looking\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text2text-generation\", \n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_new_tokens=150\n",
    ")\n",
    "\n",
    "response = generator(prompt)[0][\"generated_text\"]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "999d8ab1-6326-43e8-9c73-fc3d63a5d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answer = (\n",
    "    \"Sherlock Holmes is described as a man who becomes deeply absorbed \"\n",
    "    \"in unsolved problems and spends long periods analyzing facts.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2af00-10d9-49b9-9843-223ddfdde8db",
   "metadata": {},
   "source": [
    "**EVALUATION METRICS - ROUGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d426df7e-04e1-4b22-ac7e-8296a239935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: Score(precision=0.03225806451612903, recall=0.09090909090909091, fmeasure=0.047619047619047616)\n",
      "ROUGE-L: Score(precision=0.03225806451612903, recall=0.09090909090909091, fmeasure=0.047619047619047616)\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rougeL\"],\n",
    "    use_stemmer=True\n",
    ")\n",
    "\n",
    "scores = scorer.score(reference_answer, response)\n",
    "\n",
    "print(\"ROUGE-1:\", scores[\"rouge1\"])\n",
    "print(\"ROUGE-L:\", scores[\"rougeL\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52fa17-d103-4f5b-bbfc-0ad2526de149",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "The ROUGE scores are low because ROUGE measures exact n-gram overlap, while the generated answer is a paraphrased description rather than a word-for-word match with the reference answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f077b-b8d1-4831-b840-61e384b62c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain_env)",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
